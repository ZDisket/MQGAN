{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQGAN Audio Reconstruction Demo\n",
    "\n",
    "**Assumptions:**\n",
    "- Audio files are in a folder specified by `AUDIO_FOLDER`.\n",
    "- Checkpoints for the preencoder (VQGAN) and ISTFT models exist in directories specified by `PREENCODER_MODEL_DIR` and `ISTFT_MODEL_DIR`.\n",
    "- Configuration files for spectrogram extraction (`spec_config.yaml`) and model parameters (`model_config.yaml`) are available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchaudio\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Import custom modules\n",
    "from scripted_preencoder import ScriptedPreEncoder\n",
    "from istftnetfe import ISTFTNetFE, TorchSTFT\n",
    "from convert_spectrograms import TorchMelSpectrogramExtractor # Use the project's extractor\n",
    "\n",
    "# --- Configuration ---\n",
    "AUDIO_FOLDER = \"path/to/your/audio/files\"  # TODO: Change this path\n",
    "PREENCODER_MODEL_DIR = \"path/to/preencoder/checkpoint\"  # TODO: Change this path\n",
    "ISTFT_MODEL_DIR = \"path/to/istft/checkpoint\"  # TODO: Change this path\n",
    "SPEC_CONFIG_PATH = \"configs/spec_config_hifimusic.yaml\" # Use the project's spec config\n",
    "MODEL_CONFIG_PATH = \"configs/model_config_hifimusic.yaml\" # Use the project's model config\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "MAX_FILES_TO_PROCESS = 5  # Limit for demo\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "\n",
    "# Load configurations\n",
    "with open(SPEC_CONFIG_PATH, 'r') as f:\n",
    "    spec_config = yaml.safe_load(f)\n",
    "print(f\"Loaded spectrogram config from {SPEC_CONFIG_PATH}\")\n",
    "\n",
    "with open(MODEL_CONFIG_PATH, 'r') as f:\n",
    "    model_config = yaml.safe_load(f)\n",
    "print(f\"Loaded model config from {MODEL_CONFIG_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Models ---\n",
    "\n",
    "try:\n",
    "    preencoder = ScriptedPreEncoder(PREENCODER_MODEL_DIR, device=DEVICE)\n",
    "    print(f\"PreEncoder loaded. Mel channels: {preencoder.mel_channels}\")\n",
    "    # Verify config matches model\n",
    "    assert preencoder.mel_channels == spec_config['spectrogram']['n_mel_channels'], \\\n",
    "        f\"Mel channels mismatch: preencoder ({preencoder.mel_channels}) vs config ({spec_config['spectrogram']['n_mel_channels']})\"\n",
    "except Exception as e:\n",
    "    print(f\"Error loading PreEncoder: {e}\")\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    # Initialize ISTFTNetFE with dummy components, then load the traced generator\n",
    "    dummy_stft = TorchSTFT(filter_length=1024, hop_length=256, win_length=1024) # Placeholder\n",
    "    dummy_gen = torch.nn.Identity() # Placeholder\n",
    "    istft_model = ISTFTNetFE(dummy_gen, dummy_stft)\n",
    "    istft_model.load_ts(ISTFT_MODEL_DIR, in_dev=DEVICE)\n",
    "    print(f\"ISTFT model loaded. Sampling rate: {istft_model.sampling_rate}\")\n",
    "    # Verify config matches model\n",
    "    assert istft_model.sampling_rate == spec_config['spectrogram']['sampling_rate'], \\\n",
    "        f\"Sampling rate mismatch: istft ({istft_model.sampling_rate}) vs config ({spec_config['spectrogram']['sampling_rate']})\"\n",
    "except Exception as e:\n",
    "    print(f\"Error loading ISTFT model: {e}\")\n",
    "    raise\n",
    "\n",
    "# Initialize the spectrogram extractor using the loaded config\n",
    "mel_extractor = TorchMelSpectrogramExtractor(spec_config['spectrogram'])\n",
    "mel_extractor.transf = mel_extractor.transf.to(DEVICE) # Move extractor to device if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper Functions ---\n",
    "\n",
    "def load_and_preprocess_audio(filepath, target_sr=spec_config['spectrogram']['sampling_rate']):\n",
    "    \"\"\"Loads an audio file, resamples to target_sr, and converts to mono.\"\"\"\n",
    "    waveform, original_sr = torchaudio.load(filepath)\n",
    "    \n",
    "    # Convert to mono if necessary\n",
    "    if waveform.shape[0] > 1:\n",
    "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "    \n",
    "    # Resample if necessary\n",
    "    if original_sr != target_sr:\n",
    "        resampler = torchaudio.transforms.Resample(orig_freq=original_sr, new_freq=target_sr)\n",
    "        waveform = resampler(waveform)\n",
    "    \n",
    "    return waveform, target_sr\n",
    "\n",
    "def plot_spectrogram(spectrogram, title=\"Spectrogram\", ax=None):\n",
    "    \"\"\"Plots a spectrogram.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(10, 4))\n",
    "    \n",
    "    # Assuming spectrogram is (batch, time, channels) or (time, channels)\n",
    "    if spectrogram.ndim == 3:\n",
    "        spec_to_plot = spectrogram[0].cpu().numpy()\n",
    "    else:\n",
    "        spec_to_plot = spectrogram.cpu().numpy()\n",
    "        \n",
    "    im = ax.imshow(spec_to_plot.T, aspect='auto', origin='lower', interpolation='none')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Time Frames\")\n",
    "    ax.set_ylabel(\"Frequency Bins\")\n",
    "    plt.colorbar(im, ax=ax, format=\"%+2.0f dB\")\n",
    "    if ax is None:\n",
    "        plt.show()\n",
    "\n",
    "def process_audio_file(filepath):\n",
    "    \"\"\"Full processing pipeline for a single audio file.\"\"\"\n",
    "    print(f\"\\n--- Processing {os.path.basename(filepath)} ---\")\n",
    "    \n",
    "    # 1. Load and preprocess audio\n",
    "    waveform, sr = load_and_preprocess_audio(filepath, spec_config['spectrogram']['sampling_rate'])\n",
    "    print(f\"Loaded waveform shape: {waveform.shape}, Sample rate: {sr}\")\n",
    "    \n",
    "    # --- Original Audio Display ---\n",
    "    display(Audio(waveform.numpy(), rate=sr))\n",
    "    \n",
    "    # 2. Create Spectrogram using the project's extractor\n",
    "    # The extractor expects (1, T) and outputs (T, n_mels)\n",
    "    with torch.no_grad():\n",
    "        mel_spec = mel_extractor.get_mel_from_wav(waveform.to(DEVICE)) # (T, n_mels)\n",
    "    # Add batch dimension for preencoder: (1, T, n_mels)\n",
    "    mel_spec_input = mel_spec.unsqueeze(0) # (1, T, n_mels)\n",
    "    print(f\"Created log-mel-spectrogram shape: {mel_spec_input.shape}\")\n",
    "    \n",
    "    # Plot original spectrogram\n",
    "    plot_spectrogram(mel_spec_input.squeeze(0), title=\"Original Log-Mel Spectrogram\")\n",
    "    \n",
    "    # 3. Encode to tokens\n",
    "    with torch.no_grad():\n",
    "        indices = preencoder.encode(mel_spec_input)\n",
    "    print(f\"Encoded indices shape: {indices.shape}\")\n",
    "    \n",
    "    # 4. Decode tokens back to spectrogram\n",
    "    with torch.no_grad():\n",
    "        reconstructed_spec = preencoder.decode(indices)\n",
    "    print(f\"Reconstructed spectrogram shape: {reconstructed_spec.shape}\")\n",
    "    \n",
    "    # Plot reconstructed spectrogram\n",
    "    plot_spectrogram(reconstructed_spec.squeeze(0), title=\"Reconstructed Log-Mel Spectrogram\")\n",
    "    \n",
    "    # 5. Reconstruct audio from spectrogram using ISTFT model\n",
    "    # The ISTFT model expects input like (B, C, T)\n",
    "    # Transpose the reconstructed spec: (1, T, n_mels) -> (1, n_mels, T)\n",
    "    reconstructed_spec_input = reconstructed_spec.permute(0, 2, 1).to(DEVICE) # Shape: (1, n_mels, T)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Use the generator part of the ISTFT model to get spec and phase\n",
    "        spec_out, phase_out = istft_model.gen(reconstructed_spec_input)\n",
    "        # Then use the full ISTFT model to get waveform\n",
    "        reconstructed_waveform = istft_model(spec_out) # Uses internal stft.inverse\n",
    "    \n",
    "    reconstructed_waveform = reconstructed_waveform.cpu()\n",
    "    print(f\"Reconstructed waveform shape: {reconstructed_waveform.shape}\")\n",
    "    \n",
    "    # --- Reconstructed Audio Display ---\n",
    "    display(Audio(reconstructed_waveform.numpy(), rate=istft_model.sampling_rate))\n",
    "\n",
    "    return waveform, mel_spec_input, indices, reconstructed_spec, reconstructed_waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "\n",
    "# Find audio files\n",
    "audio_extensions = spec_config['io']['audio_extensions']\n",
    "audio_files = []\n",
    "for ext in audio_extensions:\n",
    "    # Handle extensions with or without leading dot\n",
    "    pattern_ext = ext if ext.startswith('.') else f'.{ext}'\n",
    "    audio_files.extend(glob.glob(os.path.join(AUDIO_FOLDER, f'*{pattern_ext}')))\n",
    "\n",
    "if not audio_files:\n",
    "    print(f\"No audio files found in {AUDIO_FOLDER}\")\n",
    "else:\n",
    "    print(f\"Found {len(audio_files)} audio files. Processing up to {MAX_FILES_TO_PROCESS}.\")\n",
    "    for i, filepath in enumerate(audio_files[:MAX_FILES_TO_PROCESS]):\n",
    "        try:\n",
    "            process_audio_file(filepath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
